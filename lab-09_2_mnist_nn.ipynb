{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9_2 MNIST with neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve MNIST with multiple layers of neurons to enhance performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.ReLU` is a class in the PyTorch library that applies the Rectified Linear Unit (ReLU) activation function to the input data. The ReLU activation function is defined as:\n",
    "\n",
    "$ \\text{ReLU}(x) = \\max(0, x) $\n",
    "\n",
    "This means that it outputs the input directly if it is positive; otherwise, it outputs zero. ReLU is widely used in neural networks because it helps to introduce non-linearity into the model while being computationally efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6645,  0.6646,  0.7159,  ..., -0.3040, -0.8945, -0.7977],\n",
       "        [-1.2045,  2.4545, -1.8073,  ..., -1.7139, -0.0451,  0.3864],\n",
       "        [ 0.3414,  0.3114, -1.9218,  ..., -0.4525, -0.6849,  0.9663],\n",
       "        ...,\n",
       "        [ 1.3915, -0.4048,  0.2338,  ..., -0.8257, -0.8397,  1.9816],\n",
       "        [ 1.0414,  0.2130, -0.0417,  ...,  1.7541, -0.6454, -0.0821],\n",
       "        [-0.1162, -1.2692,  0.8201,  ..., -0.8303, -0.5022,  0.0583]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization\n",
    "torch.nn.init.normal_(linear1.weight)\n",
    "torch.nn.init.normal_(linear2.weight)\n",
    "torch.nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights determine how the outputs of the previous neuron are combined to produce the final output.\n",
    "\n",
    "This code initializes the weights of three linear layers (linear1, linear2, and linear3) using the normal_ function from the torch.nn.init module. The normal_ function fills the weights with values drawn from a normal (Gaussian) distribution.\n",
    "\n",
    "The point of initializing the weights in this manner is to ensure that the neural network starts with weights that are not too large or too small, and break the symmetry, which can help with the convergence of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 128.811523438\n",
      "Epoch: 0002 cost = 35.830200195\n",
      "Epoch: 0003 cost = 23.081176758\n",
      "Epoch: 0004 cost = 16.084297180\n",
      "Epoch: 0005 cost = 11.661833763\n",
      "Epoch: 0006 cost = 8.553230286\n",
      "Epoch: 0007 cost = 6.407429218\n",
      "Epoch: 0008 cost = 4.845437527\n",
      "Epoch: 0009 cost = 3.704708338\n",
      "Epoch: 0010 cost = 2.775542498\n",
      "Epoch: 0011 cost = 2.172554731\n",
      "Epoch: 0012 cost = 1.680796385\n",
      "Epoch: 0013 cost = 1.240631223\n",
      "Epoch: 0014 cost = 1.162401319\n",
      "Epoch: 0015 cost = 0.868149042\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9472000002861023\n",
      "Label:  6\n",
      "Prediction:  6\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.targets.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.targets[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
